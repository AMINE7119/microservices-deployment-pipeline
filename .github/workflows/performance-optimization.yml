# Performance Optimization CI/CD Pipeline
# Integrates cost monitoring, performance testing, and resource optimization

name: Performance Optimization Pipeline

on:
  push:
    branches: [main, develop, 'feature/phase*']
    paths:
      - 'services/**'
      - 'infrastructure/**'
      - 'optimization/**'
      - '.github/workflows/**'
  pull_request:
    branches: [main, develop]
    paths:
      - 'services/**'
      - 'infrastructure/**'
      - 'optimization/**'
  schedule:
    # Run performance analysis daily at 3 AM
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test to run'
        required: true
        default: 'baseline'
        type: choice
        options:
        - baseline
        - load
        - stress
        - spike
        - endurance
      cost_analysis:
        description: 'Run cost analysis'
        required: false
        default: true
        type: boolean

permissions:
  contents: read
  packages: write
  security-events: write
  pull-requests: write
  issues: write

env:
  REGISTRY: ghcr.io
  PROMETHEUS_URL: http://prometheus.monitoring.svc.cluster.local:9090
  GRAFANA_URL: http://grafana.monitoring.svc.cluster.local:3000

jobs:
  # Performance baseline analysis
  performance-baseline:
    name: Performance Baseline Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    outputs:
      baseline-results: ${{ steps.baseline.outputs.results }}
      cost-per-request: ${{ steps.cost-analysis.outputs.cost-per-request }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup K6
        uses: grafana/setup-k6-action@v1
        with:
          k6-version: '0.47.0'
          
      - name: Configure kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
          
      - name: Setup kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
      - name: Verify cluster connectivity
        run: |
          kubectl cluster-info
          kubectl get nodes
          
      - name: Run baseline performance test
        id: baseline
        run: |
          cd optimization/performance/testing
          
          # Set test environment
          export BASE_URL="http://api-gateway.microservices.svc.cluster.local:8080"
          export TEST_TYPE="${{ github.event.inputs.test_type || 'baseline' }}"
          
          # Run K6 test with cost tracking
          k6 run \
            --out json=baseline-results.json \
            --out prometheus=http://prometheus-pushgateway.monitoring.svc.cluster.local:9091 \
            --env BASE_URL=$BASE_URL \
            --env TEST_TYPE=$TEST_TYPE \
            k6-performance-tests.js
          
          # Extract key metrics
          TOTAL_REQUESTS=$(jq -r '.metrics.http_reqs.count' baseline-results.json)
          AVG_RESPONSE_TIME=$(jq -r '.metrics.http_req_duration.avg' baseline-results.json)
          ERROR_RATE=$(jq -r '.metrics.http_req_failed.rate' baseline-results.json)
          
          echo "total-requests=$TOTAL_REQUESTS" >> $GITHUB_OUTPUT
          echo "avg-response-time=$AVG_RESPONSE_TIME" >> $GITHUB_OUTPUT
          echo "error-rate=$ERROR_RATE" >> $GITHUB_OUTPUT
          
          # Save results for comparison
          echo "results=$(cat baseline-results.json | jq -c)" >> $GITHUB_OUTPUT
          
      - name: Cost analysis
        id: cost-analysis
        run: |
          # Query current resource costs
          COST_QUERY="sum(increase(total_cost[1h]))"
          REQUESTS_QUERY="sum(increase(http_requests_total[1h]))"
          
          # Mock cost calculation for CI environment
          TOTAL_COST=0.50  # $0.50 per hour estimated
          TOTAL_REQUESTS="${{ steps.baseline.outputs.total-requests }}"
          
          if [ "$TOTAL_REQUESTS" -gt "0" ]; then
            COST_PER_REQUEST=$(echo "scale=6; $TOTAL_COST / $TOTAL_REQUESTS" | bc)
          else
            COST_PER_REQUEST=0
          fi
          
          echo "cost-per-request=$COST_PER_REQUEST" >> $GITHUB_OUTPUT
          echo "total-cost=$TOTAL_COST" >> $GITHUB_OUTPUT
          
          # Cost efficiency analysis
          if (( $(echo "$COST_PER_REQUEST > 0.001" | bc -l) )); then
            echo "‚ö†Ô∏è High cost per request: \$$COST_PER_REQUEST" >> $GITHUB_STEP_SUMMARY
            echo "cost-alert=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Cost per request within target: \$$COST_PER_REQUEST" >> $GITHUB_STEP_SUMMARY
            echo "cost-alert=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: performance-baseline-results
          path: |
            optimization/performance/testing/baseline-results.json
          retention-days: 30
          
  # Resource utilization analysis
  resource-analysis:
    name: Resource Utilization Analysis
    runs-on: ubuntu-latest
    needs: performance-baseline
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install requests kubernetes pyyaml
          
      - name: Configure kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
          
      - name: Setup kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
      - name: Analyze resource utilization
        id: resource-analysis
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          from kubernetes import client, config
          
          # Mock Prometheus queries for CI environment
          def mock_prometheus_query(query):
              # Return mock data based on query type
              if "cpu_usage" in query:
                  return {"data": {"result": [{"value": ["1234567890", "0.65"]}]}}
              elif "memory" in query:
                  return {"data": {"result": [{"value": ["1234567890", "0.72"]}]}}
              elif "cost" in query:
                  return {"data": {"result": [{"value": ["1234567890", "0.25"]}]}}
              return {"data": {"result": []}}
          
          # Analyze CPU utilization
          cpu_query = "avg(rate(container_cpu_usage_seconds_total[5m])) / avg(container_spec_cpu_quota / container_spec_cpu_period)"
          cpu_data = mock_prometheus_query(cpu_query)
          
          if cpu_data["data"]["result"]:
              cpu_utilization = float(cpu_data["data"]["result"][0]["value"][1])
              print(f"Average CPU Utilization: {cpu_utilization:.1%}")
              
              if cpu_utilization < 0.3:
                  print("::warning::CPU utilization is low - consider rightsizing")
                  with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                      f.write("cpu-recommendation=rightsize-down\n")
              elif cpu_utilization > 0.8:
                  print("::warning::CPU utilization is high - consider scaling up")
                  with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                      f.write("cpu-recommendation=scale-up\n")
              else:
                  print("‚úÖ CPU utilization is optimal")
                  with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                      f.write("cpu-recommendation=optimal\n")
          
          # Analyze memory utilization
          memory_query = "avg(container_memory_working_set_bytes) / avg(container_spec_memory_limit_bytes)"
          memory_data = mock_prometheus_query(memory_query)
          
          if memory_data["data"]["result"]:
              memory_utilization = float(memory_data["data"]["result"][0]["value"][1])
              print(f"Average Memory Utilization: {memory_utilization:.1%}")
              
              if memory_utilization < 0.3:
                  print("::warning::Memory utilization is low - consider rightsizing")
                  with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                      f.write("memory-recommendation=rightsize-down\n")
              elif memory_utilization > 0.8:
                  print("::warning::Memory utilization is high - consider scaling up")
                  with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                      f.write("memory-recommendation=scale-up\n")
              else:
                  print("‚úÖ Memory utilization is optimal")
                  with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                      f.write("memory-recommendation=optimal\n")
          
          # Generate rightsizing recommendations
          recommendations = []
          
          if cpu_utilization < 0.3 and memory_utilization < 0.3:
              recommendations.append("Consider reducing resource requests by 25-30%")
          elif cpu_utilization > 0.8 or memory_utilization > 0.8:
              recommendations.append("Consider increasing resource limits by 20-25%")
          
          if len(recommendations) > 0:
              with open(os.environ["GITHUB_OUTPUT"], "a") as f:
                  f.write(f"recommendations={json.dumps(recommendations)}\n")
          
          EOF
          
      - name: Generate resource optimization report
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## üìä Resource Utilization Analysis
          
          ### Current Utilization
          - CPU Recommendation: ${{ steps.resource-analysis.outputs.cpu-recommendation }}
          - Memory Recommendation: ${{ steps.resource-analysis.outputs.memory-recommendation }}
          
          ### Optimization Opportunities
          ${{ steps.resource-analysis.outputs.recommendations || 'No immediate optimizations needed' }}
          
          ### Next Steps
          - Review VPA recommendations in the cluster
          - Consider implementing automated rightsizing
          - Monitor cost trends for optimization opportunities
          EOF
          
  # Cost optimization analysis
  cost-optimization:
    name: Cost Optimization Analysis
    runs-on: ubuntu-latest
    needs: [performance-baseline, resource-analysis]
    if: github.event.inputs.cost_analysis == 'true' || github.event.inputs.cost_analysis == null
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install requests pandas numpy
          
      - name: Analyze cost trends
        id: cost-trends
        run: |
          python3 << 'EOF'
          import json
          import os
          from datetime import datetime, timedelta
          
          # Mock cost data for analysis
          cost_data = {
              "current_hourly_cost": 0.50,
              "daily_cost": 12.00,
              "monthly_projection": 360.00,
              "cost_per_request": float("${{ needs.performance-baseline.outputs.cost-per-request }}"),
              "spot_instance_savings": 0.35
          }
          
          # Cost efficiency analysis
          print("## üí∞ Cost Analysis Report")
          print(f"Current hourly cost: ${cost_data['current_hourly_cost']:.2f}")
          print(f"Daily cost: ${cost_data['daily_cost']:.2f}")
          print(f"Monthly projection: ${cost_data['monthly_projection']:.2f}")
          print(f"Cost per request: ${cost_data['cost_per_request']:.6f}")
          print(f"Spot instance savings: {cost_data['spot_instance_savings']:.1%}")
          
          # Generate recommendations
          recommendations = []
          
          if cost_data['cost_per_request'] > 0.001:
              recommendations.append("High cost per request - optimize resource allocation")
          
          if cost_data['spot_instance_savings'] < 0.5:
              recommendations.append("Increase spot instance usage to reduce costs")
          
          if cost_data['monthly_projection'] > 500:
              recommendations.append("Monthly costs trending high - review resource usage")
          
          # Calculate potential savings
          spot_savings = cost_data['monthly_projection'] * 0.6  # 60% savings with spots
          rightsizing_savings = cost_data['monthly_projection'] * 0.2  # 20% savings
          total_potential_savings = spot_savings + rightsizing_savings
          
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
              f.write(f"monthly-cost={cost_data['monthly_projection']}\n")
              f.write(f"potential-savings={total_potential_savings:.2f}\n")
              f.write(f"recommendations={json.dumps(recommendations)}\n")
          
          EOF
          
      - name: Generate cost optimization report
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## üí∞ Cost Optimization Analysis
          
          ### Current Costs
          - Monthly projection: $$${{ steps.cost-trends.outputs.monthly-cost }}
          - Cost per request: $$${{ needs.performance-baseline.outputs.cost-per-request }}
          
          ### Optimization Opportunities
          - Potential monthly savings: $$${{ steps.cost-trends.outputs.potential-savings }}
          
          ### Recommendations
          ${{ steps.cost-trends.outputs.recommendations }}
          
          ### Action Items
          - [ ] Enable more spot instances
          - [ ] Implement automated rightsizing
          - [ ] Review unused resources
          - [ ] Optimize data transfer costs
          EOF
          
  # Performance regression detection
  performance-regression:
    name: Performance Regression Detection
    runs-on: ubuntu-latest
    needs: performance-baseline
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download baseline results
        uses: actions/download-artifact@v4
        with:
          name: performance-baseline-results
          path: ./current-results
          
      - name: Compare with previous baseline
        id: regression-check
        run: |
          # Mock regression detection for CI
          CURRENT_RESPONSE_TIME="${{ needs.performance-baseline.outputs.avg-response-time }}"
          BASELINE_RESPONSE_TIME="450"  # Mock baseline
          
          echo "Current response time: ${CURRENT_RESPONSE_TIME}ms"
          echo "Baseline response time: ${BASELINE_RESPONSE_TIME}ms"
          
          # Calculate percentage change
          if [ -n "$CURRENT_RESPONSE_TIME" ] && [ -n "$BASELINE_RESPONSE_TIME" ]; then
            CHANGE=$(echo "scale=2; (($CURRENT_RESPONSE_TIME - $BASELINE_RESPONSE_TIME) / $BASELINE_RESPONSE_TIME) * 100" | bc)
            echo "Performance change: ${CHANGE}%"
            
            if (( $(echo "$CHANGE > 10" | bc -l) )); then
              echo "::error::Performance regression detected: ${CHANGE}% increase in response time"
              echo "regression=true" >> $GITHUB_OUTPUT
              echo "change=${CHANGE}" >> $GITHUB_OUTPUT
            elif (( $(echo "$CHANGE < -10" | bc -l) )); then
              echo "‚úÖ Performance improvement detected: ${CHANGE}% decrease in response time"
              echo "improvement=true" >> $GITHUB_OUTPUT
              echo "change=${CHANGE}" >> $GITHUB_OUTPUT
            else
              echo "‚úÖ No significant performance change"
              echo "regression=false" >> $GITHUB_OUTPUT
              echo "change=${CHANGE}" >> $GITHUB_OUTPUT
            fi
          fi
          
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const regression = '${{ steps.regression-check.outputs.regression }}';
            const improvement = '${{ steps.regression-check.outputs.improvement }}';
            const change = '${{ steps.regression-check.outputs.change }}';
            const costPerRequest = '${{ needs.performance-baseline.outputs.cost-per-request }}';
            
            let emoji = 'üìä';
            let status = 'No significant change';
            
            if (regression === 'true') {
              emoji = '‚ö†Ô∏è';
              status = `Performance regression detected: ${change}% increase`;
            } else if (improvement === 'true') {
              emoji = 'üöÄ';
              status = `Performance improvement: ${Math.abs(change)}% decrease`;
            }
            
            const comment = `## ${emoji} Performance Analysis
            
            ### Performance Impact
            - **Status**: ${status}
            - **Cost per request**: $${costPerRequest}
            
            ### Performance Metrics
            - Response time change: ${change}%
            - Error rate: ${{ needs.performance-baseline.outputs.error-rate }}
            
            ### Recommendations
            ${regression === 'true' ? '- üîç Investigate performance regression causes\n- ‚ö° Consider optimization before merging' : ''}
            ${improvement === 'true' ? '- ‚úÖ Great job on performance improvements!' : ''}
            
            <details>
            <summary>üìà Detailed Results</summary>
            
            [View detailed performance report in Actions](${context.payload.pull_request.html_url}/checks)
            </details>`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
            
  # Deploy optimizations
  deploy-optimizations:
    name: Deploy Performance Optimizations
    runs-on: ubuntu-latest
    needs: [performance-baseline, resource-analysis, cost-optimization]
    if: github.ref == 'refs/heads/main' && needs.resource-analysis.outputs.cpu-recommendation != 'optimal'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Configure kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
          
      - name: Setup kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          
      - name: Apply performance optimizations
        run: |
          echo "Applying performance optimization configurations..."
          
          # Deploy rightsizing automation
          kubectl apply -f optimization/cost-management/rightsizing/
          
          # Update HPA configurations based on analysis
          kubectl apply -f optimization/performance/scaling/
          
          # Deploy cost monitoring
          kubectl apply -f optimization/cost-management/finops-dashboard/
          
          # Apply performance monitoring
          kubectl apply -f optimization/performance/monitoring/
          
      - name: Verify deployments
        run: |
          echo "Verifying performance optimization deployments..."
          
          # Check rightsizing controller
          kubectl wait --for=condition=available --timeout=300s deployment/rightsizing-controller -n monitoring
          
          # Check cost monitoring
          kubectl wait --for=condition=available --timeout=300s deployment/kubecost-cost-analyzer -n kubecost
          
          # Verify HPA status
          kubectl get hpa -A
          
          echo "‚úÖ Performance optimizations deployed successfully"
          
      - name: Generate deployment summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          ## üöÄ Performance Optimizations Deployed
          
          ### Applied Optimizations
          - ‚úÖ Automated rightsizing controller
          - ‚úÖ Enhanced HPA configurations
          - ‚úÖ Cost monitoring dashboard
          - ‚úÖ Performance monitoring stack
          
          ### Expected Benefits
          - Reduced resource waste
          - Improved cost efficiency
          - Better performance monitoring
          - Automated scaling optimization
          
          ### Monitoring
          - Check Grafana dashboards for cost trends
          - Monitor rightsizing recommendations
          - Review HPA scaling events
          EOF